{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **MODELLING AND EVALUATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Find the most efficient algorithm for regression , fine tune it and validate it.\n",
        "* Validate hypothesis\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Data cleaning pipeline and feature engineering pipeline\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* End to end ML pipeline, which is validated and ready for deployment\n",
        "* pipeline versions\n",
        "* train and test set - features and target\n",
        "\n",
        "## Additional Comments\n",
        " \n",
        " * Pipeline versions saved at outputs/datasets/predict_price/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/pp5_project_heritage_housing/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/pp5_project_heritage_housing'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Initial Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1460, 24)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>...</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>856</td>\n",
              "      <td>854.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>706</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>548</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>65.0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>61</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>856</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>978</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>284</td>\n",
              "      <td>NaN</td>\n",
              "      <td>460</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1262</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>920</td>\n",
              "      <td>866.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Mn</td>\n",
              "      <td>486</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>434</td>\n",
              "      <td>0.0</td>\n",
              "      <td>608</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>68.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>42</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>920</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>216</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>540</td>\n",
              "      <td>NaN</td>\n",
              "      <td>642</td>\n",
              "      <td>Unf</td>\n",
              "      <td>...</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>756</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1145</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Av</td>\n",
              "      <td>655</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>490</td>\n",
              "      <td>0.0</td>\n",
              "      <td>836</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>84.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>84</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1145</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
              "0       856     854.0           3.0           No         706          GLQ   \n",
              "1      1262       0.0           3.0           Gd         978          ALQ   \n",
              "2       920     866.0           3.0           Mn         486          GLQ   \n",
              "3       961       NaN           NaN           No         216          ALQ   \n",
              "4      1145       NaN           4.0           Av         655          GLQ   \n",
              "\n",
              "   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotFrontage  \\\n",
              "0        150            0.0         548          RFn  ...         65.0   \n",
              "1        284            NaN         460          RFn  ...         80.0   \n",
              "2        434            0.0         608          RFn  ...         68.0   \n",
              "3        540            NaN         642          Unf  ...         60.0   \n",
              "4        490            0.0         836          RFn  ...         84.0   \n",
              "\n",
              "   MasVnrArea OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  WoodDeckSF  \\\n",
              "0       196.0          61            5            7          856         0.0   \n",
              "1         0.0           0            8            6         1262         NaN   \n",
              "2       162.0          42            5            7          920         NaN   \n",
              "3         0.0          35            5            7          756         NaN   \n",
              "4       350.0          84            5            8         1145         NaN   \n",
              "\n",
              "   YearBuilt  YearRemodAdd  SalePrice  \n",
              "0       2003          2003     208500  \n",
              "1       1976          1976     181500  \n",
              "2       2001          2002     223500  \n",
              "3       1915          1970     140000  \n",
              "4       2000          2000     250000  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"outputs/datasets/collection/house_price_records.csv\") \n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Split data into train and test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Train set: (1168, 23) (1168,) \n",
            "* Test set: (292, 23) (292,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df.drop(['SalePrice'], axis=1) ,\n",
        "                                    df['SalePrice'],\n",
        "                                    test_size=0.2,\n",
        "                                    random_state=0\n",
        "                                    )\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import necessary modules and data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspace/.pip-modules/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  from pandas import MultiIndex, Int64Index\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "### Data Cleaning\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "from feature_engine.selection import DropFeatures\n",
        "from feature_engine.imputation import CategoricalImputer\n",
        "from feature_engine.imputation import RandomSampleImputer\n",
        "\n",
        "### Feature Engineering\n",
        "from feature_engine import creation\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "from feature_engine import transformation as vt\n",
        "from feature_engine.outliers import Winsorizer\n",
        "\n",
        "### Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### Feature Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "### ML algorithms \n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Combine data cleaning and feature engineering pipeline steps and add model as a last step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pipeline optimization\n",
        "def PipelineOptimization(model):\n",
        "  pipeline_base = Pipeline([\n",
        "    # Data cleaning (copied from Data Cleaning notebook)\n",
        "     ( 'drop',  DropFeatures(features_to_drop=['EnclosedPorch', 'GarageYrBlt', 'WoodDeckSF']) ),\n",
        "    ( 'categorical',  CategoricalImputer(imputation_method='missing',\n",
        "                                     fill_value='None',\n",
        "                                     variables=['GarageFinish']) ),\n",
        "    ( 'random_sample',  RandomSampleImputer(\n",
        "                                     variables=['LotFrontage' ,\n",
        "                                     'BsmtFinType1','2ndFlrSF','MasVnrArea']) ),\n",
        "    ( 'mean',  MeanMedianImputer(imputation_method='mean',\n",
        "                                     variables=['BedroomAbvGr']) ),\n",
        "\n",
        "    # Feature engineering (copied from Feature Engineering notebook)\n",
        "    ( 'OrdinalCategoricalEncoder', OrdinalEncoder(encoding_method='arbitrary',\n",
        "                                                variables = ['BsmtExposure',\n",
        "                                                            'BsmtFinType1',\n",
        "                                                            'GarageFinish',\n",
        "                                                            'KitchenQual'])),\n",
        "    (\"Winsoriser_iqr\",Winsorizer(capping_method='iqr', fold=3, tail='both', \n",
        "                                                  variables=['1stFlrSF',\n",
        "                                                            'GarageArea',\n",
        "                                                            'GrLivArea',\n",
        "                                                            'YearBuilt',\n",
        "                                                            'TotalBsmtSF',]) ),\n",
        "    \n",
        "    (\"feat_scaling\", StandardScaler() ),\n",
        "\n",
        "    (\"model\", model ),\n",
        "    ])\n",
        "\n",
        "  return pipeline_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Look for most optimal ML algorithm "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For that, we will use a custom function and GridSearchCV. For hyperparameters, we will use parameters suggested by official documentation as a starting point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will igore linear regression model to begin with, because our data cleaning and feature engineering pipeline is simpl and contains correlated features that can affect its prediction. Tree based and ensamble methods are more tolerant to that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_quick_search = {\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
        "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
        "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "# From Scikit-learn Unit 6\n",
        "params_quick_search = {\n",
        "\n",
        "    \"DecisionTreeRegressor\": {'model__max_depth': [None,4, 15],\n",
        "                             'model__min_samples_split': [2,50],\n",
        "                             'model__min_samples_leaf': [1,50],\n",
        "                             'model__max_leaf_nodes': [None,50],\n",
        "        },\n",
        "\n",
        "    \"RandomForestRegressor\": {'model__n_estimators': [100,50, 140],\n",
        "                             'model__max_depth': [None,4, 15],\n",
        "                             'model__min_samples_split': [2,50],\n",
        "                             'model__min_samples_leaf': [1,50],\n",
        "                             'model__max_leaf_nodes': [None,50],\n",
        "        },\n",
        "\n",
        "    \"ExtraTreesRegressor\": {'model__n_estimators': [100,50,150],\n",
        "        'model__max_depth': [None, 3, 15],\n",
        "        'model__min_samples_split': [2, 50],\n",
        "        'model__min_samples_leaf': [1,50],\n",
        "        },\n",
        "\n",
        "    \"AdaBoostRegressor\": {'model__n_estimators': [50,25,80,150],\n",
        "                          'model__learning_rate':[1,0.1, 2],\n",
        "                          'model__loss':['linear', 'square', 'exponential'],\n",
        "        },\n",
        "\n",
        "    \"GradientBoostingRegressor\": {'model__n_estimators': [100,50,140],\n",
        "                                  'model__learning_rate':[0.1, 0.01, 0.001],\n",
        "                                  'model__max_depth': [3,15, None],\n",
        "                                  'model__min_samples_split': [2,50],\n",
        "                                  'model__min_samples_leaf': [1,50],\n",
        "                                  'model__max_leaf_nodes': [None,50],\n",
        "        },\n",
        "\n",
        "    \"XGBRegressor\": {'model__n_estimators': [30,80,200],\n",
        "                    'model__max_depth': [None, 3, 15],\n",
        "                    'model__learning_rate': [0.01,0.1,0.001],\n",
        "                    'model__gamma': [0, 0.1],\n",
        "        },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's use these two functions as agruments to the following code that will help us to find most suitable model.\n",
        "\n",
        "The code is taken from walkthrough project 2 notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "            model=  PipelineOptimization(self.models[key])\n",
        "\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring)\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs    \n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns], self.grid_searches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's search for most suitable model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looks like GradientBoostinRegressor performs the best on mean_score. The score is 0.86 , which is above the target of 0.75."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model= grid_search_summary.iloc[0,0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "216 different combinations were tried when the code above was run. So, I belive the model is optimised for now and we don't need to do additional tuning. (However, uder  performance on test set can warrant having a second look. We will check that soon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_parameters = grid_search_pipelines[best_model].best_params_\n",
        "best_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check the model performance on test set after defining pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "best_regressor_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Performance check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's define a custom function (adopted from Scikit Learn Notebook) to evaluate performance on train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def regression_performance(X_train, y_train, X_test, y_test,pipeline):\n",
        "\tprint(\"Model Evaluation \\n\")\n",
        "\tprint(\"* Train Set\")\n",
        "\tregression_evaluation(X_train,y_train,pipeline)\n",
        "\tprint(\"* Test Set\")\n",
        "\tregression_evaluation(X_test,y_test,pipeline)\n",
        "\n",
        "def regression_evaluation(X,y,pipeline):\n",
        "  prediction = pipeline.predict(X)\n",
        "  print('R2 Score:', r2_score(y, prediction).round(3))  \n",
        "  print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))  \n",
        "  print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))  \n",
        "  print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y, prediction)).round(3))\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "def regression_evaluation_plots(X_train, y_train, X_test, y_test,pipeline, alpha_scatter=0.5):\n",
        "  pred_train = pipeline.predict(X_train)\n",
        "  pred_test = pipeline.predict(X_test)\n",
        "\n",
        "\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
        "  sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
        "  sns.lineplot(x=y_train , y=y_train, color='red', ax=axes[0])\n",
        "  axes[0].set_xlabel(\"Actual\")\n",
        "  axes[0].set_ylabel(\"Predictions\")\n",
        "  axes[0].set_title(\"Train Set\")\n",
        "\n",
        "  sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
        "  sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
        "  axes[1].set_xlabel(\"Actual\")\n",
        "  axes[1].set_ylabel(\"Predictions\")\n",
        "  axes[1].set_title(\"Test Set\")\n",
        "  plt.savefig(f'docs/regression_plots/regression_performance.png', bbox_inches='tight')  \n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regression_performance(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- R2 score for Train set is 0.94 and for Test set is 0.81 , both of them are above the threshold of 0.75\n",
        "\n",
        "- R2 score on Train set indicates overfitting. Let's se if we can do some hyperparameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save first version of pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "version = 'v1'\n",
        "file_path = f'outputs/ml_pipeline/predict_price/{version}'\n",
        "\n",
        "try:\n",
        "  os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "joblib.dump(value=best_regressor_pipeline, filename=f\"{file_path}/regression_pipeline.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Hyper parameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The R2 score difference between Test and Train set is 0.13. \n",
        "\n",
        "Let's attempt to reduce that by understanding the model and playing with hyper parameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_search = {\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
        "}\n",
        "params_search = {\n",
        "    \"GradientBoostingRegressor\": {\n",
        "        'model__learning_rate': [0.1],\n",
        "        'model__max_depth': [15],   # changing model max_depth from None to 4 to prevent complexity\n",
        "        'model__n_estimators': [140]\n",
        "        }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Refit the pipeline\n",
        "\n",
        "# search for algo and hyper parameters\n",
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)\n",
        "\n",
        "# save result matrix\n",
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extract best model and its parameters with\n",
        "best_model= grid_search_summary.iloc[0,0]\n",
        "best_parameters = grid_search_pipelines[best_model].best_params_\n",
        "\n",
        "# get the best pipeline\n",
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "\n",
        "# check its regression performance\n",
        "regression_performance(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looks like deeper the model, the more it overfits. Let's limit the model max depth by trying some lower numbers along with larger n estimator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params_search = {\n",
        "        \"GradientBoostingRegressor\": {    \n",
        "        'model__learning_rate': [0.05, 0.1],    # attempting slower learning rate\n",
        "        'model__max_depth': [3, 4, 5],          # limiting model max depth                  \n",
        "        'model__min_samples_leaf': [50, 100],   \n",
        "        'model__min_samples_split': [2, 10],\n",
        "        'model__n_estimators': [140, 200]       # trying higher n estimators\n",
        "        },\n",
        "}\n",
        "\n",
        "# Refit the pipeline\n",
        "\n",
        "# search for algo and hyper parameters\n",
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)\n",
        "\n",
        "# save result matrix\n",
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "\n",
        "# extract best model and its parameters with\n",
        "best_model= grid_search_summary.iloc[0,0]\n",
        "best_parameters = grid_search_pipelines[best_model].best_params_\n",
        "\n",
        "# get the best pipeline\n",
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "\n",
        "# check its regression performance\n",
        "regression_performance(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The previous R2 score for Train and Test were 0.94 and 0.81.\n",
        "\n",
        "Now the R2 score for Train and Test set is 0.91 and 0.81 \n",
        "\n",
        "Here, we reduced the model's max depth from None to 3 (or sometimes returns 4), which reduced the overfitting from 0.94 to 0.91. \n",
        "\n",
        "Other hyper parameters seems to be optimised enough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save second version of pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "version = 'v2'\n",
        "file_path = f'outputs/ml_pipeline/predict_price/{version}'\n",
        "\n",
        "try:\n",
        "  os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "joblib.dump(value=best_regressor_pipeline, filename=f\"{file_path}/regression_pipeline.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Rewrite pipeline with additional step - Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To reduce overfitting, we can consider adding \"feature selection\" as a pipeline step. Let's rewrite the entire pipeline with it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pipeline optimization\n",
        "def PipelineOptimization(model):\n",
        "  pipeline_base = Pipeline([\n",
        "    # Data cleaning (copied from Data Cleaning notebook)\n",
        "     ( 'drop',  DropFeatures(features_to_drop=['EnclosedPorch', 'GarageYrBlt', 'WoodDeckSF'])),\n",
        "    ( 'categorical',  CategoricalImputer(imputation_method='missing',\n",
        "                                     fill_value='None',\n",
        "                                     variables=['GarageFinish'])),\n",
        "    ( 'random_sample',  RandomSampleImputer(\n",
        "                                     variables=['LotFrontage' ,\n",
        "                                     'BsmtFinType1','2ndFlrSF','MasVnrArea'])),\n",
        "    ( 'mean',  MeanMedianImputer(imputation_method='mean',\n",
        "                                     variables=['BedroomAbvGr']) ),\n",
        "\n",
        "    # Feature engineering (copied from Feature Engineering notebook)\n",
        "    ( 'OrdinalCategoricalEncoder', OrdinalEncoder(encoding_method='arbitrary',\n",
        "                                                variables = ['BsmtExposure',\n",
        "                                                            'BsmtFinType1',\n",
        "                                                            'GarageFinish',\n",
        "                                                            'KitchenQual'])),\n",
        "    (\"Winsoriser_iqr\",Winsorizer(capping_method='iqr', fold=3, tail='both', \n",
        "                                                  variables=['1stFlrSF',\n",
        "                                                            'GarageArea',\n",
        "                                                            'GrLivArea',\n",
        "                                                            'YearBuilt',\n",
        "                                                            'TotalBsmtSF',])),\n",
        "    (\"feat_scaling\", StandardScaler()),\n",
        "    (\"feat_selection\",  SelectFromModel(model, threshold=\"mean\")),\n",
        "    (\"model\", model),\n",
        "    ])\n",
        "\n",
        "  return pipeline_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's rerun the pipeline and check the performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_search = {\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
        "}\n",
        "params_search = {\n",
        "    \"GradientBoostingRegressor\": {\n",
        "        'model__learning_rate': [0.1],\n",
        "        'model__max_depth': [3],\n",
        "        'model__min_samples_leaf': [50],\n",
        "        'model__min_samples_split': [2],\n",
        "        'model__n_estimators': [140]}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# search for algo and hyper parameters\n",
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)\n",
        "\n",
        "# save result matrix\n",
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "\n",
        "# extract best model and its parameters with\n",
        "best_model= grid_search_summary.iloc[0,0]\n",
        "best_parameters = grid_search_pipelines[best_model].best_params_\n",
        "\n",
        "# get the best pipeline\n",
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "\n",
        "# check its regression performance\n",
        "regression_performance(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "save third version of pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "version = 'v3'\n",
        "file_path = f'outputs/ml_pipeline/predict_price/{version}'\n",
        "\n",
        "try:\n",
        "  os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "joblib.dump(value=best_regressor_pipeline, filename=f\"{file_path}/regression_pipeline.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The R2 score for Train set are now much closer.\n",
        "\n",
        "However, R2 score for test is 0.76  very close to criteria of 0.75\n",
        "\n",
        "If we compare the R2 score of the pipeline without feature selection step, it is 0.81. \n",
        "\n",
        "That means feature selection step is filtering out far too many features. There is a possiblility the datset contains a few features with equal imporatace and some of them are not being passed on to model.\n",
        "\n",
        "So, let's lower the threshold from default \"mean\" to \"0.75*mean\"\n",
        "\n",
        "(official documentation : https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pipeline optimization\n",
        "def PipelineOptimization(model):\n",
        "  pipeline_base = Pipeline([\n",
        "    # Data cleaning (copied from Data Cleaning notebook)\n",
        "     ( 'drop',  DropFeatures(features_to_drop=['EnclosedPorch', 'GarageYrBlt', 'WoodDeckSF'])),\n",
        "    ( 'categorical',  CategoricalImputer(imputation_method='missing',\n",
        "                                     fill_value='None',\n",
        "                                     variables=['GarageFinish'])),\n",
        "    ( 'random_sample',  RandomSampleImputer(\n",
        "                                     variables=['LotFrontage' ,\n",
        "                                     'BsmtFinType1','2ndFlrSF','MasVnrArea'])),\n",
        "    ( 'mean',  MeanMedianImputer(imputation_method='mean',\n",
        "                                     variables=['BedroomAbvGr']) ),\n",
        "\n",
        "    # Feature engineering (copied from Feature Engineering notebook)\n",
        "    ( 'OrdinalCategoricalEncoder', OrdinalEncoder(encoding_method='arbitrary',\n",
        "                                                variables = ['BsmtExposure',\n",
        "                                                            'BsmtFinType1',\n",
        "                                                            'GarageFinish',\n",
        "                                                            'KitchenQual'])),\n",
        "    (\"Winsoriser_iqr\",Winsorizer(capping_method='iqr', fold=3, tail='both', \n",
        "                                                  variables=['1stFlrSF',\n",
        "                                                            'GarageArea',\n",
        "                                                            'GrLivArea',\n",
        "                                                            'YearBuilt',\n",
        "                                                            'TotalBsmtSF',])),\n",
        "    (\"feat_scaling\", StandardScaler()),\n",
        "    (\"feat_selection\",  SelectFromModel(model, threshold=\"0.75*mean\")), # reduced threshold\n",
        "    (\"model\", model),\n",
        "    ])\n",
        "\n",
        "  return pipeline_base\n",
        "\n",
        "\n",
        "# search for algo and hyper parameters\n",
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)\n",
        "\n",
        "# save result matrix\n",
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "\n",
        "# extract best model and its parameters with\n",
        "best_model= grid_search_summary.iloc[0,0]\n",
        "best_parameters = grid_search_pipelines[best_model].best_params_\n",
        "\n",
        "# get the best pipeline\n",
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "\n",
        "# check its regression performance\n",
        "regression_performance(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will consider this an optimised version of pipeline as R2 score for test set is 0.79, which is higher than critera. But on the other side, we have tried reducing model overfitting. as much as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save fourth version of pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "version = 'v4'\n",
        "file_path = f'outputs/ml_pipeline/predict_price/{version}'\n",
        "\n",
        "try:\n",
        "  os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "joblib.dump(value=best_regressor_pipeline, filename=f\"{file_path}/regression_pipeline.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# after data cleaning and feature engineering, the features may have changes\n",
        "# how many data cleaning and feature engineering steps does your pipeline have?\n",
        "data_cleaning_feat_eng_steps = 6\n",
        "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
        "                                        .transform(X_train)\n",
        "                                        .columns)\n",
        "\n",
        "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
        ")].to_list()\n",
        "\n",
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
        "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
        "    .sort_values(by='Importance', ascending=False)\n",
        ")\n",
        "\n",
        "# Most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save feature imporatnce plot\n",
        "\n",
        "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
        "\n",
        "## Save to docs folder for documentation\n",
        "plt.savefig(f'docs/images/features_importance.png', bbox_inches='tight') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| **Pipeline**                                 \t| **Version** \t| Mean R2  (Train) \t| Mean R2  (Test) \t| delta R2 \t|\n",
        "|----------------------------------------------\t|-------------\t|------------------\t|-----------------\t|----------\t|\n",
        "| gradientboost with default hyper param       \t| v1          \t| 0.94             \t| 0.81            \t| 0.13     \t|\n",
        "| parameter optimised                          \t| v2          \t| 0.91             \t| 0.81            \t| 0.10     \t|\n",
        "| additional feature selelection pipeline step \t| v3          \t| 0.83             \t| 0.76            \t| 0.7      \t|\n",
        "| feature selection optimised                  \t| v4          \t| 0.87             \t| 0.79            \t| 0.8      \t|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Gradient boosting is the most efficient algorithm. The test set passes the critera of R2 score of 0.75 and above\n",
        "\n",
        "* Hypothesis - bigger than property higher the price - Ture\n",
        "\n",
        "* Hypothesis - higher the quality better the price - True\n",
        "\n",
        "* Hypothesis - Newer the property higher the price - False (it does not impact as much as quality and size)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
