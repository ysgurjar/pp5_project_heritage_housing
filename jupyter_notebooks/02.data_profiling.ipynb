{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **DATA PROFILING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Take a closer look at data. Understand data types, distribution, gaps (i.e. missing values).\n",
        "## Inputs\n",
        "\n",
        "* Raw data (house_prices_records.csv)\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* One cleaned dataset of house_prices_records that is ready for Exploratory Data Analysis.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In the Data Collection phase, we inspected inherited_houses.csv file manually. It was easy to do so because of only 4 raws of data. We concluded that the only difference from \"house_prices_records.csv\" is the absence of SalePrice. For the data cleaning purpose, we are only focusing primary dataset i.e. (house_price_records.csv), because inherited house dataset is (1) irrelavant for EDA and (2) complete and ready to use as it is.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Data Profiling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Schema validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check that data confirms to schema outlined in metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make sure to work on a copy of data\n",
        "\n",
        "import pandas as pd\n",
        "df_source_data=pd.read_csv(\"inputs/datasets/raw/house_prices_records.csv\")\n",
        "df=df_source_data.copy()\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are 24 columns. Column name description is provided in metadata for additional context. This can help determine data type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data type conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This step is important so correct categorical variables are identified for profiling down the line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_data_col=('BsmtExposure','BsmtFinType1','GarageFinish','KitchenQual','OverallCond','OverallQual','YearBuilt','YearRemodAdd')\n",
        "\n",
        "for cat in cat_data_col:\n",
        "    df[cat]=df[cat].astype('category')\n",
        "\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run detailing profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note : A copy of report is saved and provided down the line, to avoid re running cell again and again\n",
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(df=df)\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "profile.to_file(output_file='outputs/profiling_report_output.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primary Findings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Variables**\n",
        "\n",
        "- Therere are 24 variables in total. 16 Variables are numerical and 8 are categorical.\n",
        "\n",
        "- All eight categorical variables are ordinal in nature. four of them are numerically encoded and four are not.\n",
        "    - For analysis purpose YearBuilt and YearRemodAdd have been treated as categorical ordinal value. This will provide context for \"an apartment build before year X.. or after year Y\"\n",
        "\n",
        "- All numerical variables conforms to min-max range provided in metadata.\n",
        "    - However, there are no apartments where OverallCond = 10 (excellent)\n",
        "    \n",
        "- All categorical variable conforms to categories provided in metadata. \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Missing values and possible approaches\n",
        "\n",
        "- ```SalePrice```which will be our target variable down the line, has zero missing values. Good news for analysis and prediction.\n",
        "\n",
        "- ```EnclosedPorch``` and ```WoodDeckSF``` columns have about 90% data missing. Consider to drop them for analysis.\n",
        "\n",
        "- ```LotFrontage```has 17.7 % missing values. However, it seems to be highly overall correlated with ```LotArea```, It also makes sense in physical world. Bigger the lot area, the higher the chances that LotFrontage (i.e. linear feet of street connected to property) is bigger. So, we can leverage this relation for missing data imputaion.\n",
        "\n",
        "- ```GarageFinish```has 11.1% missing values. It seems to be highly correlated with ```GarageArea```. In phsyical world, they are independent. For example, a bigger garden does not nessarily mean high qality finish. So, we may have to look at other areas to find imputation strategies, for ex. distribution.\n",
        "\n",
        "- ```BsmtFinType1```has 7.8% missing values. It seems to be highly correlated with ```BsmtExposure```. In physical world, \"walkout or garden level walls exposure level\" and \"quality of basement\" are independent. So, perhaps this correlation is just coinsidence. So, we may have to look at other strategies for data impuration, for ex. distribution.\n",
        "\n",
        "- ```BedroomAbvGr```has 6.8% missing values. It seems to be highly correlated with ```2ndFlrSF```and ```GrLivArea```. In physical world it kind of makes sense. Having a bedroom above ground will certainly increase 2nd floor surface area. It may or may not affect above ground living area, because they may be treating bedroom area and living area seperately for record purpose. So, we can leverage first relationship to imputate data.\n",
        "\n",
        "- ```GarageYrBlt```has 5.5% missing values. It seems to be highly correlated with ```GarageArea``` , ```SalePrice```and ```YearRemodAdd```. In physical world, it may be possible that with time (GarageYrBlt), larger and larger (or smaller and smaller) garages were built. It is possible that with newer the garage, better the sales price. We can explore these relationships further for missing data imputation. \n",
        "\n",
        "If we address all of the above, it will cover almost 50% of total missing values and bring the missing value percentage at dataset level from 9.8% to nearly 5%. This is acceptable to work with for prediction purpose.\n",
        "\n",
        "Alternate argument : Sometimes including all correlated variables as features can lead to biased predictions. So, an alternate can be to include only non-correlated variables i.e. choosing only on of two highly correlated variables as feature. In that case we will not not address missing data in \"all the columns\" but only those that are relevant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are no duplicate rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Zeros\n",
        "\n",
        "- ```['2ndFlrSF','MasVnrArea','OpenPorchSF']```contains between 45-50% zero as a value. This is possible in physical world. Let's have a look at it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import seaborn\n",
        "import seaborn as sns\n",
        "\n",
        "# Apply the default theme\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "sns.pairplot(df[['2ndFlrSF','MasVnrArea','OpenPorchSF']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see from the historgram, the distribution for each variable is extremely skewed. \n",
        "\n",
        "The scatterplot confirms that the variables are also not unrelated.So, we conclude that this is just the reality. \n",
        "\n",
        "Meaning, most of the houses does not have any open porch, 2nd floor or Mass veneer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sale Price (Is there target imbalance?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Source code taken from : https://python-graph-gallery.com/24-histogram-with-a-boxplot-on-top-seaborn/\n",
        "\n",
        "sns.set_theme()\n",
        " \n",
        "# creating a figure composed of two matplotlib.Axes objects (ax_box and ax_hist)\n",
        "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
        " \n",
        "# assigning a graph to each ax\n",
        "sns.boxplot(df[\"SalePrice\"], orient=\"h\", ax=ax_box)\n",
        "sns.histplot(data=df, x=\"SalePrice\", ax=ax_hist)\n",
        " \n",
        "# Remove x axis name for the boxplot\n",
        "ax_box.set(xlabel='')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data seems to have positive Kurtosis and Positive Skewness ( right tail). Let's quantify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Kurtosis : {round(df['SalePrice'].kurt(),2)}\")\n",
        "print(f\"Skewness : {round(df['SalePrice'].skew(),2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A Skewness of 1.8 is considered very high.\n",
        "\n",
        "A Kurtosis of 6.5 is considered very high.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Down the line will to apply transformation to deal with high level of Skewness and Kurtosis to have more balanced dataset for prediction purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['SalePrice'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Around 50% of the total houses sold have prices betwen 129975 and 214000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The profiling report indicates good correlation between ```SalePrice```and ```['1stFlrSF','GarageArea','GarageYrBlt','GrLivArea','TotalBsmtSF']```. So, let's explore that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr = df.corr(method='pearson')\n",
        "df_corr.filter(['SalePrice']).sort_values(by='SalePrice', key=abs, ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up custome function to show correlation heatmap\n",
        "\n",
        "# Code adapted from EDA unit 2 Notebook 2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def heatmap_corr(data, threshold, figsize=(8,8), annot_size=8):\n",
        "  # we create the mask for the upper diagonal and\n",
        "  # show only values greater than the threshold\n",
        "  mask = np.zeros_like(data, dtype=np.bool)\n",
        "  mask[np.triu_indices_from(mask)] = True\n",
        "  mask[abs(data) < threshold] = True\n",
        "\n",
        "  # we plot the heatmap as usual\n",
        "  fig, axes = plt.subplots(figsize=(8,8))\n",
        "  sns.heatmap(data=data, annot=True, xticklabels=True, yticklabels=True,\n",
        "              mask=mask, cmap='viridis', annot_kws={\"size\": annot_size}, ax=axes,\n",
        "              linewidth=0.5\n",
        "                    )\n",
        "  plt.ylim(len(data.columns),0)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Plot heat map\n",
        "\n",
        "heatmap_corr(data= df_corr, threshold=0.6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It looks like sales prices is linearly correlated with\n",
        " \n",
        "    - Above Ground Living Area (GrLivArea)\n",
        "    - Total square feet of Basement Area (TotalBsmSF)\n",
        "    - 1st floor square feet (1stFlrSF)\n",
        "    - Garage Area (GarageArea)\n",
        "\n",
        "Note that Pearson correlation does not account for non-linear relationship. So, let's explore that with ```Spearman```. We will repeat the steps mentioned above, but now with spearman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr = df.corr(method='spearman')\n",
        "df_corr.filter(['SalePrice']).sort_values(by='SalePrice', key=abs, ascending=False)\n",
        "heatmap_corr(data= df_corr, threshold=0.6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It does not reveal any additional relationship for sales price. However, it does reveal strong correlation between LotFrontage and LotArea that was previous not discovered in pearson correlation study. \n",
        "\n",
        "Let's plot all of these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_plotting=df[['SalePrice','1stFlrSF','2ndFlrSF','GarageArea','GrLivArea','LotArea','TotalBsmtSF']]\n",
        "df_plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.pairplot(data=df_plotting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The pairplot above reveals that \n",
        "- Sale prices typically increases with TotalBasmtSF, GrLivArea and 1stFlrSF. Meaning, larger the house, higher the sale price. This is representative of reality.\n",
        "\n",
        "Let's have a closer look and see which of these variables have good predictive power for Sales price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Predictive power score"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
