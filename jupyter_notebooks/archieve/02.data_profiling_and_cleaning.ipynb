{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **DATA PROFILING and CLEANING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Take a closer look at data. Understand data types, distribution, gaps (i.e. missing values), duplicates and address it.\n",
        "## Inputs\n",
        "\n",
        "* Raw data (house_prices_records.csv)\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* One cleaned dataset of house_prices_records that is ready for Exploratory Data Analysis.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In the Data Collection phase, we inspected inherited_houses.csv file manually. It was easy to do so because of only 4 raws of data. We concluded that the only difference from \"house_prices_records.csv\" is the absence of SalePrice. For the data cleaning purpose, we are only focusing primary dataset i.e. (house_price_records.csv), because inherited house dataset is (1) irrelavant for EDA and (2) complete and ready to use as it is.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Data Profiling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Schema validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check that data confirms to schema outlined in metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make sure to work on a copy of data\n",
        "\n",
        "import pandas as pd\n",
        "df_source_data=pd.read_csv(\"inputs/datasets/raw/house_prices_records.csv\")\n",
        "df=df_source_data.copy()\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are 24 columns. Column name description is provided in metadata for additional context. This can help determine data type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial Data profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(df=df, minimal=True)\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import lib to dispaly images\n",
        "from PIL import Image\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img = Image.open('docs/images/profilereport_flags.jpg')\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```EnclosedPorch``` and ```WoodDeckSF``` contains less than 15% data. Hence, we cannot use them for further correlation analysis or for predictive purpose.\n",
        "\n",
        "We can ask data collector why these values are missing and if missing value mean anything to uncover some more insights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```[2ndFlrSF,MasVnrArea,OpenPorchSF]```contains between 40% to 60% zeros. This is concerning. Let's have a look at their distribution of other values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find rows where all three columns are zero\n",
        "zero_rows = df[(df['2ndFlrSF'] == 0) & (df['MasVnrArea'] == 0) & (df['OpenPorchSF'] == 0)]\n",
        "\n",
        "# Count the number of such rows\n",
        "num_zero_rows = zero_rows.shape[0]\n",
        "\n",
        "num_zero_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider real life scenario, it is very unlikely to have all three values zero at the same time. \n",
        "\n",
        "It could be possible that the data in this rows is corrupted. However we are not sure.\n",
        "\n",
        "**However, it is important to note that 271 out of 1460 rows is around 18% of your original dataset. That is a lot of data.**\n",
        "\n",
        "Let's see if we can have rows where four or more columns have missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for rows where four or more columns have missing values\n",
        "rows_with_four_or_more_missing = df[df.isnull().sum(axis=1) >= 4]\n",
        "\n",
        "# Display the number of such rows\n",
        "num_rows_with_four_or_more_missing = rows_with_four_or_more_missing.shape[0]\n",
        "\n",
        "# Print the number of rows with four or more missing values\n",
        "print(f'Number of rows with four or more missing values: {num_rows_with_four_or_more_missing}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "110 out of 1460 rows is less than 10% of the data. We can \"assume\" that these rows are of low data quality because there is a pattern in missing data and drop them from analysis. This is also to give us best chance as \"imputating only randomly missing data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### section wrap up : Now we know which rows to drop and column to drop and why"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a dataframe with all rows except those with four or more missing values\n",
        "df_dropped_rows = df.drop(rows_with_four_or_more_missing.index)\n",
        "\n",
        "# Drop the EnclosedPorch and WoodDeckSF columns\n",
        "df_dropped_rows_cols = df_dropped_rows.drop(columns=['EnclosedPorch', 'WoodDeckSF'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data distribution and correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at each variable's distribution and its correlation with other variables. This will help us understand data and affact imputation strategy down the lie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_data_col=('BsmtExposure','BsmtFinType1','GarageFinish','KitchenQual','OverallCond','OverallQual')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_copy=df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for cat in cat_data_col:\n",
        "    print(cat)\n",
        "    df_copy[cat]=df_copy[cat].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_copy.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#data=sns.load_dataset(df_copy)\n",
        "sns.pairplot(df_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(df=df_copy)\n",
        "profile.to_notebook_iframe()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
