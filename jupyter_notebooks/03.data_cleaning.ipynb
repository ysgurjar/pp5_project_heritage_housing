{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **DATA CLEANING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Evaluate Missing data\n",
        "* Cleaning data\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/house_price_records.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* outputs/datasets/collection/cleaned_house_price_records.csv\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* ```EnclosedPorch``` and ```WoodDeckSF``` columns have about 90% data missing. Consider to drop them for analysis.\n",
        "\n",
        "* Imputate missing data\n",
        "\n",
        "* Create data cleaning pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/pp5_project_heritage_housing/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/pp5_project_heritage_housing'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plotting lib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# for data cleaning\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Drop features with lot of missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As discussed in Sale Price Study notebook, we will drop two columns  ```EnclosedPorch``` and ```WoodDeckSF``` columns have about 90% data missing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>...</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>856</td>\n",
              "      <td>854.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>706</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>548</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>65.0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>61</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>856</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>978</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>284</td>\n",
              "      <td>NaN</td>\n",
              "      <td>460</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1262</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>920</td>\n",
              "      <td>866.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Mn</td>\n",
              "      <td>486</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>434</td>\n",
              "      <td>0.0</td>\n",
              "      <td>608</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>68.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>42</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>920</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>216</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>540</td>\n",
              "      <td>NaN</td>\n",
              "      <td>642</td>\n",
              "      <td>Unf</td>\n",
              "      <td>...</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>756</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1145</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Av</td>\n",
              "      <td>655</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>490</td>\n",
              "      <td>0.0</td>\n",
              "      <td>836</td>\n",
              "      <td>RFn</td>\n",
              "      <td>...</td>\n",
              "      <td>84.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>84</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1145</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
              "0       856     854.0           3.0           No         706          GLQ   \n",
              "1      1262       0.0           3.0           Gd         978          ALQ   \n",
              "2       920     866.0           3.0           Mn         486          GLQ   \n",
              "3       961       NaN           NaN           No         216          ALQ   \n",
              "4      1145       NaN           4.0           Av         655          GLQ   \n",
              "\n",
              "   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotFrontage  \\\n",
              "0        150            0.0         548          RFn  ...         65.0   \n",
              "1        284            NaN         460          RFn  ...         80.0   \n",
              "2        434            0.0         608          RFn  ...         68.0   \n",
              "3        540            NaN         642          Unf  ...         60.0   \n",
              "4        490            0.0         836          RFn  ...         84.0   \n",
              "\n",
              "   MasVnrArea OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  WoodDeckSF  \\\n",
              "0       196.0          61            5            7          856         0.0   \n",
              "1         0.0           0            8            6         1262         NaN   \n",
              "2       162.0          42            5            7          920         NaN   \n",
              "3         0.0          35            5            7          756         NaN   \n",
              "4       350.0          84            5            8         1145         NaN   \n",
              "\n",
              "   YearBuilt  YearRemodAdd  SalePrice  \n",
              "0       2003          2003     208500  \n",
              "1       1976          1976     181500  \n",
              "2       2001          2002     223500  \n",
              "3       1915          1970     140000  \n",
              "4       2000          2000     250000  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make sure to work on a copy of data\n",
        "df_source_data=pd.read_csv(\"outputs/datasets/collection/house_price_records.csv\")\n",
        "df=df_source_data.copy()\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Split Train and Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TrainSet shape: (1168, 24) \n",
            "TestSet shape: (292, 24)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "TrainSet, TestSet, _, __ = train_test_split(\n",
        "                                        df,\n",
        "                                        df['SalePrice'],\n",
        "                                        test_size=0.2,\n",
        "                                        random_state=0)\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop two variables\n",
        "variables_method = ['EnclosedPorch','WoodDeckSF']\n",
        "\n",
        "from feature_engine.selection import DropFeatures\n",
        "imputer = DropFeatures(features_to_drop=variables_method)\n",
        "imputer.fit(TrainSet)\n",
        "\n",
        "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We don't need to evaluate distribution effect on dropped features as it is columns we are dropping, not rows. So, let's move forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imputation for other missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have concluded the following so far from previous workbook:\n",
        "\n",
        "\n",
        "- ```LotFrontage```has 17.7 % missing values. However, ydata detailed profile report shows that it is  correlated with ```LotArea```, It also makes sense in physical world. Bigger the lot area, the higher the chances that LotFrontage (i.e. linear feet of street connected to property) is bigger. So, we can leverage this relation for missing data imputaion.\n",
        "\n",
        "- ```GarageFinish```has 11.1% missing values. However, ydata detailed profile report shows that it is  correlated with  ```GarageArea```. In phsyical world, they are independent. For example, a bigger garden does not nessarily mean high qality finish. So, we may have to look at other areas to find imputation strategies, for ex. distribution.\n",
        "\n",
        "- ```BsmtFinType1```has 7.8% missing values. However, ydata detailed profile report shows that it is  correlated with  ```BsmtExposure```. In physical world, \"walkout or garden level walls exposure level\" and \"quality of basement\" are independent. So, perhaps this correlation is just coinsidence. So, we may have to look at other strategies for data impuration, for ex. distribution.\n",
        "\n",
        "- ```BedroomAbvGr```has 6.8% missing values. However, It seems to be highly correlated with ```2ndFlrSF```and ```GrLivArea```. In physical world it does not make sense. Bedroom above ground has no relation with 2nd floor surface area and living area. So, we may have to look at other strategies for data impuration, for ex. distribution.\n",
        "\n",
        "- ```GarageYrBlt```has 5.5% missing values. However, ydata detailed profile report shows that it is  correlated with  ```GarageArea``` , ```SalePrice```and ```YearRemodAdd```. In physical world, it may be possible that with time (GarageYrBlt), larger and larger (or smaller and smaller) garages were built. It is possible that with newer the garage, better the sales price. We can explore these relationships further for missing data imputation. \n",
        "\n",
        "If we address all of the above, it will cover almost 50% of total missing values and bring the missing value percentage at dataset level from 9.8% to nearly 5%. This is acceptable to work with for prediction purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now,\n",
        "- As you can see there are two vaiables [LotFrontage,GarageYrBlt] where we can leverage regression to explore relationship with other variables and use that to fill missing data. That is multi variate data imputation.\n",
        "\n",
        "- Feaure-engine currently supports univariate imputation stategies (Source: https://feature-engine.trainindata.com/en/latest/api_doc/imputation/index.html). For multi-variate imputation stategies, we need to use iterative imputer from Scikit-learn.\n",
        "\n",
        "- This will broaden the scope of project, hence for now I decide to use univariate imputation strategies for all the variables listed above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Univariate Imputation using Feature Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Since we are modifiying rows, we need to create a custom function that will help evaluate the data cleaning effect on distribution of these variables**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adopted from Unit 9 of feature engine section\n",
        "\n",
        "def DataCleaningEffect(df_original,df_cleaned,variables_applied_with_method):\n",
        "  \"\"\"\n",
        "  Function to visualize data cleaning effect\n",
        "  \"\"\"\n",
        "  flag_count=1 # Indicate plot number\n",
        "  \n",
        "  # distinguish between numerical and categorical variables\n",
        "  categorical_variables = df_original.select_dtypes(exclude=['number']).columns \n",
        "\n",
        "  # scan over variables, \n",
        "    # first on variables that you applied the method\n",
        "    # if the variable is a numerical plot, a histogram if categorical plot a barplot\n",
        "  for set_of_variables in [variables_applied_with_method]:\n",
        "    print(\"\\n=====================================================================================\")\n",
        "    print(f\"* Distribution Effect Analysis After Data Cleaning Method in the following variables:\")\n",
        "    print(f\"{set_of_variables} \\n\\n\")\n",
        "  \n",
        "\n",
        "    for var in set_of_variables:\n",
        "      if var in categorical_variables:  # it is categorical variable: barplot\n",
        "        \n",
        "        df1 = pd.DataFrame({\"Type\":\"Original\",\"Value\":df_original[var]})\n",
        "        df2 = pd.DataFrame({\"Type\":\"Cleaned\",\"Value\":df_cleaned[var]})\n",
        "        dfAux = pd.concat([df1, df2], axis=0)\n",
        "        fig , axes = plt.subplots(figsize=(15, 5))\n",
        "        sns.countplot(hue='Type', data=dfAux, x=\"Value\",palette=['#432371',\"#FAAE7B\"])\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.xticks(rotation=90)\n",
        "        plt.legend() \n",
        "\n",
        "      else: # it is numerical variable: histogram\n",
        "\n",
        "        fig , axes = plt.subplots(figsize=(10, 5))\n",
        "        sns.histplot(data=df_original, x=var, color=\"#432371\", label='Original', kde=True,element=\"step\", ax=axes)\n",
        "        sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label='Cleaned', kde=True,element=\"step\", ax=axes)\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.legend() \n",
        "\n",
        "      plt.show()\n",
        "      flag_count+= 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
